#!/usr/bin/env python3
"""
ä½¿ç”¨read_checkpoint.pyçš„æ–¹æ³•åˆ†æä¸‰ä¸ªbaselineç®—æ³•çš„pklæ–‡ä»¶
"""
import pickle
import pandas as pd
import numpy as np
import sys

# å¯¼å…¥Itemç±»
try:
    from algorithm.base import Item
except ImportError:
    class Item:
        def __init__(self):
            self.value = ""
            self.property = {}
            self.total = 0.0
            self.scores = None

def analyze_baseline_pkl(filepath, name):
    """åˆ†æbaselineç®—æ³•çš„pklæ–‡ä»¶"""
    
    print("="*80)
    print(f"åˆ†æ {name}")
    print("="*80)
    
    try:
        with open(filepath, 'rb') as f:
            data = pickle.load(f, encoding='latin1')
    except Exception as e:
        print(f"âŒ è¯»å–æ–‡ä»¶å‡ºé”™: {e}")
        return None
    
    print(f"\næ–‡ä»¶åŒ…å«çš„é”®: {list(data.keys())}")
    
    # 1. åˆ†æfinal_pops
    if 'final_pops' in data:
        final_pops = data['final_pops']
        print(f"\nã€Final Popsã€‘")
        print(f"  æ•°é‡: {len(final_pops)}")
        
        if final_pops and hasattr(final_pops[0], 'total'):
            # æŒ‰totalæ’åº
            sorted_pops = sorted(final_pops, key=lambda x: x.total if x.total is not None else -999, reverse=True)
            top5 = sorted_pops[:5]
            
            print(f"\n  Top 5è§£:")
            print(f"  {'Rank':<6} {'Total':<12} {'Score[0]':<12} {'Score[1]':<12} {'Score[2]':<12}")
            print("  " + "-"*70)
            
            for i, item in enumerate(top5, 1):
                if hasattr(item, 'scores') and item.scores is not None and len(item.scores) >= 3:
                    print(f"  {i:<6} {item.total:<12.6f} {item.scores[0]:<12.6f} {item.scores[1]:<12.6f} {item.scores[2]:<12.6f}")
                else:
                    print(f"  {i:<6} {item.total:<12.6f} {'N/A':<12} {'N/A':<12} {'N/A':<12}")
            
            # ç»Ÿè®¡scores[0]çš„åˆ†å¸ƒ
            weight_scores = [item.scores[0] for item in final_pops if hasattr(item, 'scores') and item.scores is not None and len(item.scores) >= 1]
            if weight_scores:
                print(f"\n  Weight Score (scores[0]) ç»Ÿè®¡:")
                print(f"    èŒƒå›´: [{min(weight_scores):.6f}, {max(weight_scores):.6f}]")
                print(f"    å‡å€¼: {np.mean(weight_scores):.6f}")
                print(f"    ä¸­ä½æ•°: {np.median(weight_scores):.6f}")
                
                if min(weight_scores) < 0.01:
                    print(f"    âš ï¸  å‘ç°å¼‚å¸¸ä½çš„Weight score!")
    
    # 2. åˆ†æall_mols
    if 'all_mols' in data:
        all_mols = data['all_mols']
        print(f"\nã€All Molsã€‘")
        print(f"  æ€»æ•°: {len(all_mols)}")
        
        # æå–æ•°æ®
        extracted_data = []
        for candidate_entry in all_mols:
            item = candidate_entry[0] if isinstance(candidate_entry, (list, tuple)) and candidate_entry else candidate_entry
            if not hasattr(item, 'value') or not hasattr(item, 'property'): 
                continue
            
            prop = item.property or {}
            info = {
                'total_score': item.total,
                'scores': item.scores if hasattr(item, 'scores') else None
            }
            
            # è§£æproperty
            if 'original_results' in prop:
                original_results = prop.get('original_results', {})
                constraint_results = prop.get('constraint_results', {})
                info.update({
                    'weight': original_results.get('weight'),
                    'axial_uc_max': original_results.get('axial_uc_max'),
                    'bending_uc_max': original_results.get('bending_uc_max'),
                    'is_feasible': constraint_results.get('is_feasible'),
                    'max_uc': constraint_results.get('max_uc'),
                })
            else:
                info.update({
                    'weight': prop.get('weight'),
                    'axial_uc_max': prop.get('axial_uc_max'),
                    'bending_uc_max': prop.get('bending_uc_max'),
                })
            
            extracted_data.append(info)
        
        if extracted_data:
            df = pd.DataFrame(extracted_data)
            
            # ç»Ÿè®¡æœ‰æ•ˆæ•°æ®
            valid_df = df.dropna(subset=['weight', 'axial_uc_max', 'bending_uc_max'], how='all')
            print(f"  æœ‰æ•ˆè¯„ä¼°æ•°: {len(valid_df)}")
            
            if len(valid_df) > 0:
                print(f"\n  åŸå§‹å€¼ç»Ÿè®¡:")
                print(f"    Weight: [{valid_df['weight'].min():.2f}, {valid_df['weight'].max():.2f}], å‡å€¼={valid_df['weight'].mean():.2f}")
                print(f"    Axial UC: [{valid_df['axial_uc_max'].min():.4f}, {valid_df['axial_uc_max'].max():.4f}], å‡å€¼={valid_df['axial_uc_max'].mean():.4f}")
                print(f"    Bending UC: [{valid_df['bending_uc_max'].min():.4f}, {valid_df['bending_uc_max'].max():.4f}], å‡å€¼={valid_df['bending_uc_max'].mean():.4f}")
                
                # å¯è¡Œè§£æ¯”ä¾‹
                if 'is_feasible' in valid_df.columns:
                    feasible_count = (valid_df['is_feasible'] == 1.0).sum()
                    print(f"    å¯è¡Œè§£: {feasible_count}/{len(valid_df)} ({100*feasible_count/len(valid_df):.1f}%)")
                
                # Top 10çš„åŸå§‹å€¼
                top10_df = valid_df.nlargest(10, 'total_score')
                print(f"\n  Top 10è§£çš„åŸå§‹å€¼:")
                print(f"    {'Rank':<6} {'Total':<10} {'Weight':<10} {'Axial_UC':<10} {'Bending_UC':<10}")
                print("    " + "-"*60)
                for i, (idx, row) in enumerate(top10_df.iterrows(), 1):
                    print(f"    {i:<6} {row['total_score']:<10.4f} {row['weight']:<10.2f} {row['axial_uc_max']:<10.4f} {row['bending_uc_max']:<10.4f}")
    
    return data

def compare_baselines():
    """å¯¹æ¯”ä¸‰ä¸ªbaselineç®—æ³•"""
    
    files = {
        'GA_optimized': 'moo_results/zgca,gemini-2.5-flash-nothinking/mols/weight_axial_uc_max_bending_uc_max_sacs_geo_jk_baseline_GA_optimized_101.pkl',
        'NSGA2': 'moo_results/zgca,gemini-2.5-flash-nothinking/mols/weight_axial_uc_max_bending_uc_max_sacs_geo_jk_baseline_NSGA2_101.pkl',
        'SMSEMOA': 'moo_results/zgca,gemini-2.5-flash-nothinking/mols/weight_axial_uc_max_bending_uc_max_sacs_geo_jk_baseline_SMSEMOA_101.pkl'
    }
    
    results = {}
    for name, filepath in files.items():
        data = analyze_baseline_pkl(filepath, name)
        results[name] = data
        print("\n")
    
    # å¯¹æ¯”åˆ†æ
    print("="*80)
    print("å¯¹æ¯”åˆ†æ")
    print("="*80)
    
    print("\nã€å…³é”®å‘ç°ã€‘")
    
    # æå–final_popsçš„weight scores
    for name, data in results.items():
        if data and 'final_pops' in data:
            final_pops = data['final_pops']
            weight_scores = [item.scores[0] for item in final_pops if hasattr(item, 'scores') and item.scores is not None and len(item.scores) >= 1]
            if weight_scores:
                print(f"\n{name}:")
                print(f"  Final Pops Weight ScoreèŒƒå›´: [{min(weight_scores):.6f}, {max(weight_scores):.6f}]")
                print(f"  å‡å€¼: {np.mean(weight_scores):.6f}")
                
                if min(weight_scores) < 0.01:
                    print(f"  ğŸš¨ å¼‚å¸¸: Weight scoreå¼‚å¸¸ä½ (< 0.01)")
                    print(f"  è¿™ä¼šå¯¼è‡´hypervolumeå’Œavg_top100è™šé«˜!")

if __name__ == '__main__':
    compare_baselines()
